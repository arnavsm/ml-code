# Links

### Main Reference
[The spelled-out intro to neural networks and backpropagation: building micrograd by](https://youtu.be/VMj-3S1tku0?si=dzp5gTHmyyHrYvGT) [*Andrej Karpathy*](https://karpathy.ai/)

### Papers
- Baydin, A. G., Pearlmutter, B. A., Radul, A. A., & Siskind, J. M. (2018). Automatic differentiation in machine learning: a survey. *Journal of Machine Learning Research, 18*(153), 1–43.
https://doi.org/10.48550/arXiv.1502.05767 

- Griewank, A. (1992). Achieving logarithmic growth of temporal and spatial complexity in reverse automatic differentiation. *Optimization Methods and Software, 1*(1), 35–54. https://doi.org/10.1080/10556789208805505

- Bartholomew-Biggs, M., Brown, S., Christianson, B., & Dixon, L. (2000). Automatic differentiation of algorithms. *Journal of Computational and Applied Mathematics, 124*(1–2), 171–190. https://doi.org/10.1016/S0377-0427(00)00422-2



### Other Blogs
- [Automatic differentiation Wiki](https://en.wikipedia.org/wiki/Automatic_differentiation)
- [Overview of PyTorch Autograd Engine](https://pytorch.org/blog/overview-of-pytorch-autograd-engine/)
- [The Fundamentals of Autograd](https://pytorch.org/tutorials/beginner/introyt/autogradyt_tutorial.html)
- [Automatic Differentiation with `torch.autograd`](https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html)
- [A Gentle Introduction to `torch.autograd`](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html)
- [Reverse-mode automatic differentiation: a tutorial](https://rufflewind.com/2016-12-30/reverse-mode-automatic-differentiation)

